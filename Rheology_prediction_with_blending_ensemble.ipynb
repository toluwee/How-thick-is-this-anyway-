{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rheology_prediction_with blending ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AOkcUYKWB2To",
        "tERpJTtYB-3a",
        "ls8Pe3WThcti",
        "fGq_Ua5pORlZ",
        "kJc8hf_vBYvf",
        "hOsVjW1p-Fh6"
      ],
      "mount_file_id": "1otrYolEIpPJaj7RE0l1I6cD05Z7dgEXX",
      "authorship_tag": "ABX9TyMhGA2WExrJE7511OvWP52+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toluwee/Rheology_prediction_with_blending_ensemble/blob/main/Rheology_prediction_with_blending_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk1CpKN-7HKn"
      },
      "source": [
        "# Objective\n",
        "\n",
        " \n",
        "\n",
        "*   Predict the apparent viscosity of nanoparticle stabilized CO2 foam fracturing fluid using blending (a stacking variant) machine learning ensemble model.\n",
        "*   Determine the influence of various parameters on apparent viscosity prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfAgBWKXZhLk"
      },
      "source": [
        "# About The Dataset\n",
        "45 input data points were compiled from the published results of Fu and Liu's (2021) laboratory rheology experiments on nanoparticle-stabilized CO2-foam at high temperatures and pressure. \n",
        "\n",
        "The authors varied the temperature, concentration of nanoparticles, salinity, quality of foam, and the shear rate at constant backpressure of 1,300 psi. These variables served as input features for this analysis to predict the apparent viscosity of NP-CO2-foam when used as fracturing fluid. \n",
        "\n",
        "217 additional data records were generated from the collected dataset by polynomial interpolation to make a total of 262 records. \n",
        "\n",
        "\n",
        "The following is a description of the dataset.\n",
        "\t\t\t\t\t\n",
        "**Attribute Information:**\n",
        "\n",
        "| Position | Feature | Description |Feature Type |\n",
        "|------:|:-----|---------|---------|\n",
        "|[, 1]|\ttemp\t|Temperature, centigrade|Numerical|\n",
        "|[, 2]|\tnp_conc|\tNanoparticle conc., %wt |Numerical|\n",
        "|[, 3]|\tsalinity|\tSalinity, %wt |Numerical|\n",
        "|[, 4]|\tfoam_qual|\tFoam quality, %|Categorical|\n",
        "|[, 5]|\tshear|\tShear rate, s-1 |Numerical|\n",
        "|[, 6]|\tapp_vis|\tApparent viscosity, cp|Numerical|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOkcUYKWB2To"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbOAxQC4UIdl"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "filepath = 'https://datasciencefiles.s3.us-east-2.amazonaws.com/AppVis_Fu2.csv'\n",
        "\n",
        "dataset = pd.read_csv(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tERpJTtYB-3a"
      },
      "source": [
        "# Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGVIJVBrbBXz",
        "outputId": "dd46ed40-0717-4c10-b914-07245a2a2295"
      },
      "source": [
        "# shape\n",
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "e6OJ2EbPEDrG",
        "outputId": "8cf0b53d-125c-4f91-b3af-343e8ecfce70"
      },
      "source": [
        "dataset.sample(n=5, replace = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temp</th>\n",
              "      <th>np_conc</th>\n",
              "      <th>salinity</th>\n",
              "      <th>foam_qual</th>\n",
              "      <th>shear</th>\n",
              "      <th>app_vis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>20</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.70</td>\n",
              "      <td>3027</td>\n",
              "      <td>21.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>20</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.11</td>\n",
              "      <td>3027</td>\n",
              "      <td>8.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>20</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.70</td>\n",
              "      <td>3027</td>\n",
              "      <td>16.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>20</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.70</td>\n",
              "      <td>3027</td>\n",
              "      <td>15.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>39</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.70</td>\n",
              "      <td>4400</td>\n",
              "      <td>8.29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     temp  np_conc  salinity  foam_qual  shear  app_vis\n",
              "180    20     0.50      0.07       0.70   3027    21.15\n",
              "31     20     0.50      0.05       0.11   3027     8.29\n",
              "169    20     0.64      0.05       0.70   3027    16.10\n",
              "134    20     0.29      0.05       0.70   3027    15.35\n",
              "228    39     0.50      0.05       0.70   4400     8.29"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "_35ul1st5c-g",
        "outputId": "2a0e8ff0-a9df-4b80-f2e7-02d4c23a18a8"
      },
      "source": [
        "pd.set_option('precision', 2)\n",
        "dataset.agg(['mean','min', 'max', 'std'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temp</th>\n",
              "      <th>np_conc</th>\n",
              "      <th>salinity</th>\n",
              "      <th>foam_qual</th>\n",
              "      <th>shear</th>\n",
              "      <th>app_vis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>25.26</td>\n",
              "      <td>0.47</td>\n",
              "      <td>5.07e-02</td>\n",
              "      <td>0.60</td>\n",
              "      <td>3227.09</td>\n",
              "      <td>12.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>20.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>3.00e-02</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1338.00</td>\n",
              "      <td>2.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>72.00</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.10e-01</td>\n",
              "      <td>0.90</td>\n",
              "      <td>4400.00</td>\n",
              "      <td>34.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.53</td>\n",
              "      <td>0.11</td>\n",
              "      <td>6.03e-03</td>\n",
              "      <td>0.21</td>\n",
              "      <td>723.86</td>\n",
              "      <td>5.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       temp  np_conc  salinity  foam_qual    shear  app_vis\n",
              "mean  25.26     0.47  5.07e-02       0.60  3227.09    12.08\n",
              "min   20.00     0.05  3.00e-02       0.10  1338.00     2.63\n",
              "max   72.00     0.70  1.10e-01       0.90  4400.00    34.54\n",
              "std   12.53     0.11  6.03e-03       0.21   723.86     5.38"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls8Pe3WThcti"
      },
      "source": [
        "# Create Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vxkiXUKct6J"
      },
      "source": [
        "# Seperate output and input variables\n",
        "target = [\"app_vis\"]\n",
        "X_full,y_full = dataset.drop(target, axis=1), dataset[target]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq8JGkcSp9xK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# seperate training and test data \n",
        "train_X, test_X, y_train, y_test = train_test_split(X_full,y_full, test_size=0.2,random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGq_Ua5pORlZ"
      },
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP5J0jKTi1oQ"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(train_X)\n",
        "X_test = scaler.transform(test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3K-jKca1SHz"
      },
      "source": [
        "y_train = y_train.values.flatten()\n",
        "y_test = y_test.values.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KIxABHeL1YG"
      },
      "source": [
        "# Base Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jYX9CVyKARh"
      },
      "source": [
        "# Create function to build and compile a Keras neural network model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "\n",
        "def build_model(n_hidden=1, n_neurons=20, learning_rate = 3e-3, input_shape = X_train.shape[1:]): # explicitly state no of features as input_shape\n",
        "  model = Sequential()\n",
        "  options = {\"input_shape\": input_shape}\n",
        "\n",
        "  for layer in range(n_hidden):\n",
        "    model.add(Dense(n_neurons, activation=\"relu\", \n",
        "                    **options))\n",
        "    options ={} # so that input_shape option only applies to first layer\n",
        "  model.add(Dense(1, activation=\"linear\",  \n",
        "                  **options)) #output layer\n",
        "\n",
        "  optimizer = RMSprop(learning_rate)\n",
        "  model.compile(loss = \"mse\", optimizer = optimizer) # mse represents l2 loss\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GDmpKuGKML0"
      },
      "source": [
        "# Preprocess training and testing dataset to be suitable for polynomial regression\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures(degree=4)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4vbVJYGNOHQ"
      },
      "source": [
        "# Create base models\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "model_SVR = SVR(C= 64, degree = 5, gamma= 0.28510676478015073, kernel= 'rbf')\n",
        "model_MPR = LinearRegression()\n",
        "model_ANN = build_model()\n",
        "model_CART = DecisionTreeRegressor(random_state= 42) \n",
        "model_KNN = KNeighborsRegressor(algorithm = 'auto', leaf_size = 98, n_neighbors = 3, p = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJc8hf_vBYvf"
      },
      "source": [
        "# Blending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjtORiaRBZem",
        "outputId": "9a4b1164-0e93-4ff9-99f2-7354a5e59be4"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow import keras\n",
        "from numpy import hstack\n",
        "\n",
        "# get a list of base models\n",
        "def get_models():\n",
        "\tmodels = []\n",
        "\n",
        "\tmodels.append(('SVR', model_SVR))\n",
        "\tmodels.append(('MPR', model_MPR))\n",
        "\tmodels.append(('ANN', model_ANN))\n",
        "\tmodels.append(('CART', model_CART))\n",
        "\tmodels.append(('KNN', model_KNN))\n",
        "\treturn models\n",
        "\n",
        "# fit the blending ensemble\n",
        "def fit_ensemble(models, X_train, X_test, y_train, y_test):\n",
        "\t# fit all models on the training set and predict on hold out set\n",
        "\tmeta_X = list()\n",
        " \n",
        "\tfor name,model in models:\n",
        "\t\tif name == 'MPR':\n",
        "\t\t\t# fit in training set\n",
        "\t\t\tX_train_poly1 = PolynomialFeatures(degree=4).fit_transform(X_train)\n",
        "\t\t\tmodel.fit(X_train_poly1, y_train)\n",
        "\t\telif name == 'ANN':\n",
        "\t\t\tmodel.fit(X_train, y_train, epochs = 300, batch_size = 20, \n",
        "         validation_split = 0.2,callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "\t\telse:\n",
        "\t\t\t# fit in training set\n",
        "\t\t\tmodel.fit(X_train, y_train)\t \n",
        "\t\n",
        "\t# predict on test set\n",
        "\n",
        "\tfor name,model in models:\n",
        "\t\tif name == 'MPR':\n",
        "\t\t\tX_poly= PolynomialFeatures(degree=4).fit_transform(X_test)\n",
        "\t\t\tyhat = model.predict(X_poly) \n",
        "\t\telse:\n",
        "\t\t\tyhat = model.predict(X_test)\n",
        "\t\t\n",
        "\t\t# reshape predictions into a matrix with one column\n",
        "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
        "\t\t# store predictions as input for blending\n",
        "\t\tmeta_X.append(yhat)\n",
        "\t# create 2d array from predictions, each set is an input feature\n",
        "\tmeta_X = hstack(meta_X)\n",
        "\t# define blending model\n",
        " \n",
        "\tblender = SVR(C= 83, gamma= 0.15996237372700434, kernel= 'rbf')\n",
        "\n",
        "\t# fit on predictions from base models\n",
        "\tblender.fit(meta_X, y_test)\n",
        "\treturn blender\n",
        "\n",
        "# make a prediction with the blending ensemble\n",
        "def predict_ensemble(models, blender, X_test):\n",
        "\t# make predictions with base models\n",
        "\tmeta_X = list()\n",
        "\tfor name ,model in models:\n",
        "\t\t# predict with base model\n",
        "\t\tif name == 'MPR':\n",
        "\t\t\tX_poly= PolynomialFeatures(degree=4).fit_transform(X_test)\n",
        "\t\t\tyhat = model.predict(X_poly)\n",
        "\t\telse:\n",
        "\t\t\tyhat = model.predict(X_test)\n",
        "\n",
        "\t\t# reshape predictions into a matrix with one column\n",
        "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
        "\t\t# store prediction\n",
        "\t\tmeta_X.append(yhat)\n",
        "\t# create 2d array from predictions, each set is an input feature\n",
        "\tmeta_X = hstack(meta_X)\n",
        "\t# predict\n",
        "\treturn blender.predict(meta_X)\n",
        "\n",
        "# create the base models\n",
        "models = get_models()\n",
        "\n",
        "# train the blending ensemble\n",
        "\n",
        "\n",
        "blender = fit_ensemble(models, X_train, X_train, y_train, y_train)\n",
        "\n",
        "blender_2 = fit_ensemble(models, X_train, X_test, y_train, y_test)\n",
        "\n",
        "Blended_pred_train = predict_ensemble(models, blender, X_train)\n",
        "\n",
        "Blended_pred = predict_ensemble(models, blender_2, X_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 22ms/step - loss: 178.1446 - val_loss: 163.1702\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 168.6161 - val_loss: 156.8229\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 161.3877 - val_loss: 150.9731\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 154.4703 - val_loss: 144.9588\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 147.3988 - val_loss: 138.7167\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 140.2091 - val_loss: 132.6962\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 133.1612 - val_loss: 126.3015\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 125.9559 - val_loss: 120.1234\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 119.0943 - val_loss: 114.0213\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 112.1257 - val_loss: 107.6389\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 105.0783 - val_loss: 101.3182\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 98.0120 - val_loss: 94.8874\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 90.9118 - val_loss: 88.5768\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 84.1125 - val_loss: 82.3702\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 77.4880 - val_loss: 76.4326\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 71.0410 - val_loss: 69.8714\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 64.4970 - val_loss: 64.4428\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 58.7861 - val_loss: 58.8964\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 53.1747 - val_loss: 53.7492\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 48.2257 - val_loss: 48.8547\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 43.4486 - val_loss: 44.5104\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 39.1606 - val_loss: 40.6389\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 35.4614 - val_loss: 37.4988\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 32.3489 - val_loss: 34.4878\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 29.6294 - val_loss: 31.7658\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 27.0323 - val_loss: 29.1279\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 24.7446 - val_loss: 27.1766\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 22.9443 - val_loss: 25.4839\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 21.3630 - val_loss: 23.9028\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 19.9991 - val_loss: 22.4739\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.7103 - val_loss: 21.2593\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.5402 - val_loss: 20.1786\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.5302 - val_loss: 18.9386\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 15.5596 - val_loss: 17.8861\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.7200 - val_loss: 17.1631\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.0464 - val_loss: 16.5167\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.4805 - val_loss: 15.7935\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.9262 - val_loss: 15.1835\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.4809 - val_loss: 14.6379\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.0822 - val_loss: 14.1229\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.7380 - val_loss: 13.6794\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.4105 - val_loss: 13.2551\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.0872 - val_loss: 12.9072\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.8038 - val_loss: 12.5180\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.5197 - val_loss: 12.0349\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.1875 - val_loss: 11.6529\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9553 - val_loss: 11.4734\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.7643 - val_loss: 11.2708\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.6019 - val_loss: 11.1024\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.3577 - val_loss: 10.9053\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1946 - val_loss: 10.6873\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.9899 - val_loss: 10.4481\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8386 - val_loss: 10.2783\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5647 - val_loss: 9.9229\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4236 - val_loss: 9.7146\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2188 - val_loss: 9.5581\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.9620 - val_loss: 9.2438\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8146 - val_loss: 9.0160\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5616 - val_loss: 8.8409\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3955 - val_loss: 8.5726\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.1501 - val_loss: 8.5182\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9932 - val_loss: 8.3004\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7929 - val_loss: 8.0617\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5811 - val_loss: 7.8952\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4701 - val_loss: 7.7138\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2731 - val_loss: 7.5469\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1722 - val_loss: 7.3173\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9577 - val_loss: 7.1914\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.8317 - val_loss: 7.0158\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6509 - val_loss: 6.8463\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.5128 - val_loss: 6.6269\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3199 - val_loss: 6.5891\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2329 - val_loss: 6.4258\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0685 - val_loss: 6.2484\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9578 - val_loss: 6.0143\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7748 - val_loss: 5.9057\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6137 - val_loss: 5.7547\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5177 - val_loss: 5.6152\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3962 - val_loss: 5.3645\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2870 - val_loss: 5.1820\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1300 - val_loss: 5.0584\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0077 - val_loss: 4.8724\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8598 - val_loss: 4.8104\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.7087 - val_loss: 4.6277\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6047 - val_loss: 4.4840\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4574 - val_loss: 4.2882\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3524 - val_loss: 4.1386\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2541 - val_loss: 4.0467\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1072 - val_loss: 3.8989\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.0362 - val_loss: 3.8035\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9759 - val_loss: 3.7177\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.8347 - val_loss: 3.5874\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7609 - val_loss: 3.5026\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6572 - val_loss: 3.4912\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6181 - val_loss: 3.3197\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4824 - val_loss: 3.3344\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4766 - val_loss: 3.2056\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.3579 - val_loss: 3.1372\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.2998 - val_loss: 3.0822\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.2432 - val_loss: 2.9305\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1614 - val_loss: 2.8656\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1597 - val_loss: 2.7959\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.0879 - val_loss: 2.7098\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.0044 - val_loss: 2.6510\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9598 - val_loss: 2.5688\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9161 - val_loss: 2.5921\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8717 - val_loss: 2.5359\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8299 - val_loss: 2.3794\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8027 - val_loss: 2.2967\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7262 - val_loss: 2.2747\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.7069 - val_loss: 2.2891\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6809 - val_loss: 2.2358\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6278 - val_loss: 2.1728\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5963 - val_loss: 2.1786\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5335 - val_loss: 2.0584\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4912 - val_loss: 2.0072\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5069 - val_loss: 1.9420\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4749 - val_loss: 1.9269\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4275 - val_loss: 1.9292\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3958 - val_loss: 1.9046\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3644 - val_loss: 1.8204\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3583 - val_loss: 1.8112\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3002 - val_loss: 1.7700\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3041 - val_loss: 1.7586\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2699 - val_loss: 1.8223\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2638 - val_loss: 1.6738\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2450 - val_loss: 1.6953\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2097 - val_loss: 1.5874\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1489 - val_loss: 1.5330\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1673 - val_loss: 1.5454\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1279 - val_loss: 1.4794\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1475 - val_loss: 1.4852\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1021 - val_loss: 1.4535\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0921 - val_loss: 1.3976\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0623 - val_loss: 1.4255\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0530 - val_loss: 1.3708\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0170 - val_loss: 1.3106\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0066 - val_loss: 1.3699\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0267 - val_loss: 1.2783\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9949 - val_loss: 1.2772\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9742 - val_loss: 1.3358\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9670 - val_loss: 1.2055\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9690 - val_loss: 1.2528\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9063 - val_loss: 1.2353\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9371 - val_loss: 1.2960\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9392 - val_loss: 1.2984\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9099 - val_loss: 1.2688\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9081 - val_loss: 1.1112\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9185 - val_loss: 1.1406\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8630 - val_loss: 1.1802\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8837 - val_loss: 1.1633\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8590 - val_loss: 1.1989\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8615 - val_loss: 1.2186\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8309 - val_loss: 1.1885\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8665 - val_loss: 1.0916\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8333 - val_loss: 1.1267\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8068 - val_loss: 1.1195\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8044 - val_loss: 1.0869\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7859 - val_loss: 1.0463\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7646 - val_loss: 1.0094\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7845 - val_loss: 1.0296\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7920 - val_loss: 0.9863\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7377 - val_loss: 1.0213\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7893 - val_loss: 1.0287\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7268 - val_loss: 0.9405\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7360 - val_loss: 0.9605\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7291 - val_loss: 0.9652\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7272 - val_loss: 0.9311\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7146 - val_loss: 0.9491\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6945 - val_loss: 0.9877\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6994 - val_loss: 1.0180\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6669 - val_loss: 0.9968\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.9619\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6669 - val_loss: 0.9258\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6755 - val_loss: 0.8521\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6571 - val_loss: 0.8940\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6534 - val_loss: 0.8580\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6210 - val_loss: 0.8347\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6158 - val_loss: 0.8910\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5911 - val_loss: 0.8111\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6115 - val_loss: 0.8587\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6359 - val_loss: 0.8713\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5979 - val_loss: 0.8996\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6175 - val_loss: 0.8671\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5576 - val_loss: 0.8103\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5577 - val_loss: 0.8783\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5778 - val_loss: 0.8666\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5672 - val_loss: 0.7987\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5755 - val_loss: 0.7435\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5640 - val_loss: 0.7121\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5335 - val_loss: 0.7485\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5599 - val_loss: 0.7248\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5186 - val_loss: 0.7279\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5217 - val_loss: 0.8110\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5191 - val_loss: 0.7418\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5045 - val_loss: 0.7455\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4905 - val_loss: 0.7486\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4976 - val_loss: 0.7648\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4736 - val_loss: 0.7089\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4962 - val_loss: 0.6703\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4697 - val_loss: 0.6995\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4866 - val_loss: 0.7417\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4572 - val_loss: 0.6771\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4621 - val_loss: 0.6723\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4426 - val_loss: 0.6578\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4577 - val_loss: 0.6551\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4638 - val_loss: 0.6821\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4463 - val_loss: 0.6127\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4579 - val_loss: 0.5881\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4191 - val_loss: 0.6964\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4220 - val_loss: 0.6487\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4462 - val_loss: 0.6835\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4383 - val_loss: 0.5938\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4136 - val_loss: 0.6151\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4104 - val_loss: 0.5785\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3901 - val_loss: 0.5625\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4098 - val_loss: 0.6512\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3999 - val_loss: 0.5763\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3788 - val_loss: 0.6237\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4016 - val_loss: 0.5959\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4315 - val_loss: 0.5831\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3842 - val_loss: 0.5846\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3805 - val_loss: 0.6211\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3818 - val_loss: 0.6546\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4045 - val_loss: 0.5531\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3976 - val_loss: 0.6400\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3772 - val_loss: 0.6684\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4053 - val_loss: 0.5405\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3667 - val_loss: 0.6010\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3667 - val_loss: 0.5325\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3860 - val_loss: 0.5514\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3683 - val_loss: 0.6659\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3515 - val_loss: 0.7156\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3996 - val_loss: 0.5344\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3719 - val_loss: 0.6753\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3706 - val_loss: 0.5498\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3600 - val_loss: 0.5386\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3539 - val_loss: 0.5058\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3734 - val_loss: 0.6581\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3612 - val_loss: 0.5406\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3607 - val_loss: 0.5483\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3555 - val_loss: 0.5258\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3432 - val_loss: 0.5249\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3529 - val_loss: 0.5922\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3603 - val_loss: 0.5762\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3475 - val_loss: 0.5721\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3526 - val_loss: 0.5402\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3555 - val_loss: 0.5043\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3506 - val_loss: 0.5193\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3220 - val_loss: 0.4894\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3251 - val_loss: 0.7112\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3741 - val_loss: 0.5259\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3451 - val_loss: 0.5808\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3426 - val_loss: 0.5105\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3145 - val_loss: 0.5363\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3328 - val_loss: 0.5702\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3553 - val_loss: 0.5138\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3206 - val_loss: 0.5799\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3323 - val_loss: 0.4821\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3373 - val_loss: 0.5359\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3148 - val_loss: 0.6257\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3311 - val_loss: 0.5434\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3343 - val_loss: 0.5003\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3287 - val_loss: 0.4971\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3443 - val_loss: 0.5504\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3127 - val_loss: 0.5720\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3259 - val_loss: 0.4924\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3233 - val_loss: 0.5275\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3703 - val_loss: 0.4908\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3136 - val_loss: 0.4891\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3126 - val_loss: 0.4890\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3225 - val_loss: 0.5269\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3126 - val_loss: 0.4463\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3185 - val_loss: 0.4758\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3087 - val_loss: 0.5272\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3039 - val_loss: 0.4722\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2955 - val_loss: 0.4990\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3187 - val_loss: 0.5064\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3132 - val_loss: 0.5175\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3263 - val_loss: 0.5265\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3145 - val_loss: 0.4484\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3075 - val_loss: 0.5668\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3028 - val_loss: 0.4705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRjNgmo6c-nI"
      },
      "source": [
        "**Note**: Results will vary given the stochastic nature of the neural network algorithm. Running the example a few times and comparing the average outcome gives the reported RMSE for the Blending technique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOsVjW1p-Fh6"
      },
      "source": [
        "## Plot Predicted vs Measured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un-FxSXn-OQE",
        "outputId": "379ec627-5ac8-4e4d-de9c-e9d62516e50b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import numpy as np\n",
        "\n",
        "# Plot predicted vs Measured for Apparent Viscosity\n",
        "\n",
        "predicted = Blended_pred_train\n",
        "predicted2 = Blended_pred\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(y_test, predicted2 , c='blue', label ='test data ')\n",
        "ax.scatter(y_train, predicted, c= 'green', label ='training data')\n",
        "ax.plot(np.unique(y_test), np.poly1d(np.polyfit(y_test, predicted2, 1))(np.unique(y_test)),color='red', linestyle='dashed', lw=2)\n",
        "ax.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], color='black', linestyle='-', lw=1)\n",
        "\n",
        "ax.set_title ('Blended')\n",
        "ax.set_xlabel('Measured Apparent Viscosity, cP')\n",
        "ax.set_ylabel('Predicted Apparent Viscosity, cP')\n",
        "\n",
        "# Extend the legend to include the line of fit\n",
        "handles, labels = plt.gca().get_legend_handles_labels()\n",
        "# patch = mpatches.Patch(color='grey', label='manual patch')   \n",
        "line = Line2D([0], [0], label='test data line of fit', color='red', linestyle='dashed', lw=2)\n",
        "# handles.extend([patch, line])\n",
        "handles.extend([line])\n",
        "\n",
        "plt.legend(handles=handles)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C_MFJhDvP2o"
      },
      "source": [
        "# Evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wqp31i9CLiZ"
      },
      "source": [
        "## On Training Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiJkzlY_CLia",
        "outputId": "05b19165-325e-45a6-d9c0-59ed04dce4f4"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "rmse = round(np.abs(mean_squared_error(y_train, Blended_pred_train, squared=False)), 3 )\n",
        "mae = round(np.abs(mean_absolute_error(y_train, Blended_pred_train)), 3 )\n",
        "r_squared = round(r2_score(y_train, Blended_pred_train), 3 )\n",
        "\n",
        "print(\"RMSE on training data: \", rmse)\n",
        "print(\"MAE on training data: \", mae)\n",
        "print(\"R-squared on training data: \", r_squared)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE on training data:  0.148\n",
            "MAE on training data:  0.112\n",
            "R-squared on training data:  0.999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaFvKJYs2w6l"
      },
      "source": [
        "## On Testing Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah14WyRn40Hk",
        "outputId": "935c38af-ae26-418f-ac3d-43eb41de5f91"
      },
      "source": [
        "rmse = round(np.abs(mean_squared_error(y_test, Blended_pred, squared=False)), 3 )\n",
        "mae = round(np.abs(mean_absolute_error(y_test, Blended_pred)), 3 )\n",
        "r_squared = round(r2_score(y_test, Blended_pred), 3 )\n",
        "\n",
        "print(\"RMSE on testing data: \", rmse)\n",
        "print(\"MAE on testing data: \", mae)\n",
        "print(\"R-squared on testing data: \", r_squared)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE on testing data:  0.094\n",
            "MAE on testing data:  0.091\n",
            "R-squared on testing data:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL1z681mzf7D"
      },
      "source": [
        "# PCA Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZWtt_s4ML1N",
        "outputId": "11d7dfa2-3cd2-4fc8-f02f-e8f2993ce6ec"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# Create a PCA instance: pca\n",
        "pca = PCA(n_components=5\n",
        "          )\n",
        "df_trans= pca.fit_transform(X_train)\n",
        "\n",
        "print(\"original shape:   \", X_train.shape)\n",
        "print(\"transformed shape:\", df_trans.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original shape:    (209, 5)\n",
            "transformed shape: (209, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xzQU_g_Pq4r"
      },
      "source": [
        "import numpy as np\n",
        "#Assign labels to components\n",
        "components = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
        "\n",
        "Compo = pd.concat([pd.DataFrame(train_X.columns), pd.DataFrame(components)], axis=1)\n",
        "\n",
        "\n",
        "Compo.columns = ['Features','Principal Component 1', 'Principal Component 2',\n",
        "                               'Principal Component 3',\n",
        "                 'Principal Component 4',\n",
        "                                'Principal Component 5',\n",
        "                 \n",
        "                               ]\n",
        "to_be_changed = ['Principal Component 1', 'Principal Component 2',\n",
        "                               'Principal Component 3',\n",
        "                 'Principal Component 4',\n",
        "                                'Principal Component 5',\n",
        "]\n",
        "\n",
        "for value in to_be_changed:\n",
        "  Compo[value] = Compo[value].abs() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "k7vMlZ4WHII_",
        "outputId": "3ffc0f85-aeaa-4530-9e01-22fe91e333e5"
      },
      "source": [
        "from google.colab import data_table\n",
        "data_table.DataTable(Compo, include_index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[\"temp\",\n{\n            'v': 0.8916622193560693,\n            'f': \"0.8916622193560693\",\n        },\n{\n            'v': 0.12817400097317008,\n            'f': \"0.12817400097317008\",\n        },\n{\n            'v': 0.038949509969755665,\n            'f': \"0.038949509969755665\",\n        },\n{\n            'v': 0.19171297404265583,\n            'f': \"0.19171297404265583\",\n        },\n{\n            'v': 0.3937596673252191,\n            'f': \"0.3937596673252191\",\n        }],\n [\"np_conc\",\n{\n            'v': 0.1427091697908541,\n            'f': \"0.1427091697908541\",\n        },\n{\n            'v': 0.8194625753963071,\n            'f': \"0.8194625753963071\",\n        },\n{\n            'v': 0.2960952862809051,\n            'f': \"0.2960952862809051\",\n        },\n{\n            'v': 0.4741833137608526,\n            'f': \"0.4741833137608526\",\n        },\n{\n            'v': 0.02001597070220899,\n            'f': \"0.02001597070220899\",\n        }],\n [\"salinity\",\n{\n            'v': 0.05717329703943488,\n            'f': \"0.05717329703943488\",\n        },\n{\n            'v': 0.14144802392284897,\n            'f': \"0.14144802392284897\",\n        },\n{\n            'v': 0.956977953061717,\n            'f': \"0.956977953061717\",\n        },\n{\n            'v': 0.2561869619238851,\n            'f': \"0.2561869619238851\",\n        },\n{\n            'v': 0.0096333190369483,\n            'f': \"0.0096333190369483\",\n        }],\n [\"foam_qual\",\n{\n            'v': 0.44750168935961193,\n            'f': \"0.44750168935961193\",\n        },\n{\n            'v': 0.6513444788028209,\n            'f': \"0.6513444788028209\",\n        },\n{\n            'v': 0.1548375851073614,\n            'f': \"0.1548375851073614\",\n        },\n{\n            'v': 0.596742350612243,\n            'f': \"0.596742350612243\",\n        },\n{\n            'v': 0.014972958457245507,\n            'f': \"0.014972958457245507\",\n        }],\n [\"shear\",\n{\n            'v': 0.8974097900580513,\n            'f': \"0.8974097900580513\",\n        },\n{\n            'v': 0.05812056802678316,\n            'f': \"0.05812056802678316\",\n        },\n{\n            'v': 0.024628884560708223,\n            'f': \"0.024628884560708223\",\n        },\n{\n            'v': 0.19881369289812229,\n            'f': \"0.19881369289812229\",\n        },\n{\n            'v': 0.3949074501062335,\n            'f': \"0.3949074501062335\",\n        }]],\n        columns: [[\"string\", \"Features\"], [\"number\", \"Principal Component 1\"], [\"number\", \"Principal Component 2\"], [\"number\", \"Principal Component 3\"], [\"number\", \"Principal Component 4\"], [\"number\", \"Principal Component 5\"]],\n        columnOptions: [],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/plain": [
              "<google.colab.data_table.DataTable object>"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Features</th>\n",
              "      <th>Principal Component 1</th>\n",
              "      <th>Principal Component 2</th>\n",
              "      <th>Principal Component 3</th>\n",
              "      <th>Principal Component 4</th>\n",
              "      <th>Principal Component 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>temp</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.19</td>\n",
              "      <td>3.94e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>np_conc</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.47</td>\n",
              "      <td>2.00e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>salinity</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.26</td>\n",
              "      <td>9.63e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>foam_qual</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.50e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shear</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.20</td>\n",
              "      <td>3.95e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2D8__EjkGel"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "eX7H0JC1UXys",
        "outputId": "c2bcb68e-95cb-4db7-9b59-aca08d3ca57a"
      },
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "# perform permutation importance\n",
        "results = permutation_importance(model_SVR, X_train, y_train,\n",
        "                                 scoring='neg_mean_absolute_error',\n",
        "                                 n_repeats=10, n_jobs=-1, random_state=42)\n",
        "# get importance\n",
        "feature_importance = results.importances_mean\n",
        "\n",
        "train_X.rename(columns = {'temp': 'Temperature',\n",
        "                          'foam_qual': 'Foam quality',\n",
        "                          'shear':'Shear rate',\n",
        "                          'np_conc': 'Nanoparticle concentration',\n",
        "                          'salinity': 'Salinity'}, inplace= True)\n",
        "\n",
        "sorted_feat= sorted(zip(feature_importance, train_X), reverse=False)\n",
        "\n",
        "# Create two lists from the list of tuples created\n",
        "value,name = [list(c) for c in zip(*sorted_feat)]\n",
        "\n",
        "# Plot the features\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(y = name, width= value, color= 'r')\n",
        "\n",
        "for index, value in enumerate(value):\n",
        "  value = round(value,2)\n",
        "  plt.text(value, index, str(value))\n",
        "\n",
        "plt.xlabel('Permutation Importance (Baseline MAE - MAE post-feature-permutation)')\n",
        "# plt.ylabel(' Features ')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}